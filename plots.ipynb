{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os, json\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "\n",
    "def get_dataset_df(pdb_folder):\n",
    "    data = []\n",
    "\n",
    "    for pdb_file in os.listdir(pdb_folder):\n",
    "        if pdb_file.endswith(\".pdb\"):\n",
    "            pdb_id = os.path.splitext(pdb_file)[0]  # Extract PDB ID from filename\n",
    "            \n",
    "            try:\n",
    "                chain_a = chain_b = 0\n",
    "                with open(os.path.join(pdb_folder, pdb_file), 'r') as f:\n",
    "                    for line in f:\n",
    "                        if line.startswith('ATOM'):\n",
    "                            if line[21] == 'A':\n",
    "                                chain_a += 1\n",
    "                            elif line[21] == 'B':\n",
    "                                chain_b += 1\n",
    "\n",
    "                data.append({\n",
    "                    'pdb_path': os.path.join(pdb_folder, pdb_file),\n",
    "                    'pdb_id': pdb_id,\n",
    "                    'chain_a_length': chain_a // 8,\n",
    "                    'chain_b_length': chain_b // 8,\n",
    "                    'n_atoms': chain_a + chain_b\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {pdb_id}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def select_representative_pdbs(df, num_pdbs=10):\n",
    "    df_sorted = df.sort_values(\"n_atoms\")\n",
    "    min_pdb = df_sorted.iloc[0]\n",
    "    max_pdb = df_sorted.iloc[-1]\n",
    "    mean_pdb = df_sorted.iloc[(df_sorted[\"n_atoms\"] - df[\"n_atoms\"].mean()).abs().idxmin()]\n",
    "    \n",
    "    remaining = df_sorted.drop([min_pdb.name, max_pdb.name, mean_pdb.name])\n",
    "    sampled = remaining.iloc[np.linspace(0, len(remaining) - 1, num_pdbs - 3, dtype=int)]\n",
    "    \n",
    "    return pd.concat([min_pdb.to_frame().T, mean_pdb.to_frame().T, max_pdb.to_frame().T, sampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(\"/Users/alessio/Documents/Repos/dr_sasa_python/data/PRODIGYdataset/\")\n",
    "target_dir = Path(\"/Users/alessio/Documents/Repos/bio_lib/benchmark_af/v3/selected_prodigy_pdbs\")\n",
    "dataset_df = get_dataset_df(folder)\n",
    "selected_df = select_representative_pdbs(dataset_df)\n",
    "for f in selected_df['pdb_path']:\n",
    "    shutil.copy(Path(f), target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bio_lib.run_prodigy_custom import run\n",
    "import os\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '0.8'\n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "\n",
    "target_dir = Path(\"/Users/alessio/Documents/Repos/bio_lib/benchmark_af/v3/selected_prodigy_pdbs\")\n",
    "res = run(target_dir, output_dir=Path(\"results_cpu_benchmark_M1_selected_prodigy_pdbs\"), sphere_points=100, quiet=True, use_jax=False, benchmark=True, output_json=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_prodigy_results(results_dir, name):\n",
    "\n",
    "    all_sasa_values = []\n",
    "    all_metrics = []\n",
    "    \n",
    "    for json_file in Path(results_dir).glob(\"*.json\"):\n",
    "        with open(json_file) as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        protein_id = data[\"structure_id\"]\n",
    "        # Process SASA data\n",
    "        sasa_df = pd.DataFrame(data['sasa_data'])\n",
    "        sasa_df['protein_id'] = protein_id\n",
    "        sasa_df = sasa_df.sort_values(['chain', 'resname', 'resindex', 'atomname'])\n",
    "        all_sasa_values.append(sasa_df)\n",
    "        \n",
    "        # Process other metrics\n",
    "        metrics = {\n",
    "            'name': name,\n",
    "            'protein_id': protein_id,\n",
    "            'atoms': len(sasa_df.index),\n",
    "            'ba_val': data['ba_val'],\n",
    "            'kd': data['kd'],\n",
    "            'execution_times': data['execution_time'][\"benchmark_times\"],\n",
    "            'execution_times_min': min(data['execution_time'][\"benchmark_times\"]),\n",
    "            'execution_times_max': max(data['execution_time'][\"benchmark_times\"]), \n",
    "            'execution_times_mean': np.mean(data['execution_time'][\"benchmark_times\"]),\n",
    "            'execution_times_std': np.std(data['execution_time'][\"benchmark_times\"])\n",
    "        }\n",
    "        # Flatten nested dictionaries\n",
    "        metrics.update(data['contacts'])\n",
    "        metrics.update(data['nis'])\n",
    "        \n",
    "        all_metrics.append(metrics)\n",
    "    \n",
    "    # Combine all results\n",
    "    combined_sasa_df = pd.concat(all_sasa_values, ignore_index=True)\n",
    "    metrics_df = pd.DataFrame(all_metrics)\n",
    "    \n",
    "    return combined_sasa_df, metrics_df\n",
    "\n",
    "# Process the results\n",
    "results_dirs = { \n",
    "'./benchmark_af/v3/results_cpu_benchmark_A100_selected_prodigy_pdbs' : \"cpu_A100\",\n",
    "\"./benchmark_af/v3/results_cpu_benchmark_M1_selected_prodigy_pdbs\" : \"cpu_M1\",\n",
    "\"./benchmark_af/v3/results_gpu_benchmark_M1_selected_prodigy_pdbs\" : \"gpu_M1\",\n",
    "\"./benchmark_af/v3/results_gpu_benchmark_A100_selected_prodigy_pdbs\" : \"gpu_A100\"}\n",
    "\n",
    "all_sasa_dfs = []   \n",
    "all_metrics_dfs = []\n",
    "for results_dir, name in results_dirs.items():\n",
    "    sasa_df, metrics_df = process_prodigy_results(results_dir, name)\n",
    "    all_sasa_dfs.append(sasa_df)\n",
    "    all_metrics_dfs.append(metrics_df)\n",
    "all_sasa_dfs = pd.concat(all_sasa_dfs, ignore_index=True)\n",
    "all_metrics_dfs = pd.concat(all_metrics_dfs, ignore_index=True)\n",
    "all_metrics_dfs.to_csv(\"all_metrics_dfs.csv\")\n",
    "all_sasa_dfs.to_csv(\"all_sasa_dfs.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(28, 10))\n",
    "\n",
    "# Make the frame thicker and black for both subplots\n",
    "for ax in [ax1, ax2]:\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(2)\n",
    "        spine.set_color('black')\n",
    "\n",
    "# First subplot - Execution times vs atoms with polynomial fit\n",
    "def poly_fit(x, y, degree=2):\n",
    "    coeffs = np.polyfit(x, y, degree)\n",
    "    p = np.poly1d(coeffs)\n",
    "    return p, coeffs\n",
    "\n",
    "# Define colors for each implementation\n",
    "colors = {\n",
    "    'cpu_A100': 'blue',\n",
    "    'cpu_M1': 'green',\n",
    "    'gpu_A100': 'red',\n",
    "    'gpu_M1': 'purple'\n",
    "}\n",
    "\n",
    "for name in df['name'].unique():\n",
    "    subset = df[df['name'] == name]\n",
    "    x_i = subset['atoms'].values\n",
    "    color = colors[name]\n",
    "    \n",
    "    # Use different execution time metrics for GPU vs CPU\n",
    "    if 'gpu' in name.lower():\n",
    "        # Plot min times for GPU (post-compilation)\n",
    "        y_i_min = subset['execution_times_min'].values\n",
    "        y_i_max = subset['execution_times_max'].values\n",
    "        \n",
    "        # Plot min times with lighter color\n",
    "        ax1.scatter(x_i, y_i_min, \n",
    "                   label=f\"{name} (min, n={len(x_i)}, post-compilation)\", \n",
    "                   alpha=0.7, \n",
    "                   marker='o',\n",
    "                   color=color,\n",
    "                   facecolors='none')\n",
    "        p_min, _ = poly_fit(x_i, y_i_min, degree=2)\n",
    "        x_fit = np.linspace(min(x_i), max(x_i), 100)\n",
    "        ax1.plot(x_fit, p_min(x_fit), '--', alpha=0.5, color=color)\n",
    "        \n",
    "        # Plot max times with solid color\n",
    "        ax1.scatter(x_i, y_i_max, \n",
    "                   label=f\"{name} (max, n={len(x_i)}, with compilation)\", \n",
    "                   alpha=0.7, \n",
    "                   marker='o',\n",
    "                   color=color)\n",
    "        p_max, _ = poly_fit(x_i, y_i_max, degree=2)\n",
    "        ax1.plot(x_fit, p_max(x_fit), '--', alpha=0.5, color=color)\n",
    "    else:\n",
    "        # Use mean times for CPU\n",
    "        y_i_mean = subset['execution_times_mean'].values\n",
    "        p, _ = poly_fit(x_i, y_i_mean, degree=2)\n",
    "        \n",
    "        ax1.scatter(x_i, y_i_mean, \n",
    "                   label=f\"{name} (n={len(x_i)})\", \n",
    "                   alpha=0.7,\n",
    "                   color=color)\n",
    "        x_fit = np.linspace(min(x_i), max(x_i), 100)\n",
    "        ax1.plot(x_fit, p(x_fit), '--', alpha=0.5, color=color)\n",
    "\n",
    "ax1.set_xlabel('Number of Atoms', fontsize=12)\n",
    "ax1.set_ylabel('Execution Time (s)', fontsize=12)\n",
    "ax1.set_ylim(-0.2, None)\n",
    "ax1.set_xlim(500, None)\n",
    "\n",
    "ax1.legend(fontsize=12, loc='upper left')\n",
    "ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "ax1.set_title('Across Platforms: \\nExecution Time vs. System Size', fontsize=14)\n",
    "\n",
    "# Second subplot - Calculate mean RMSE across implementations\n",
    "metrics = [\"ba_val\", \"AA\", \"CC\", \"PP\", \"AC\", \"AP\", \"CP\", \"IC\", \n",
    "          \"chargedC\", \"polarC\", \"aliphaticC\", \"aliphatic\", \"charged\", \"polar\"]\n",
    "\n",
    "# Group by protein_id and name\n",
    "grouped_df = df.groupby([\"protein_id\", \"name\"])[metrics].mean()\n",
    "\n",
    "# Calculate mean RMSE for each metric\n",
    "rmse_results = []\n",
    "for metric in metrics:\n",
    "    metric_rmses = []\n",
    "    for protein_id in df['protein_id'].unique():\n",
    "        values = grouped_df.loc[protein_id][metric].values\n",
    "        # Calculate RMSE between all pairs of implementations\n",
    "        n = len(values)\n",
    "        rmse = 0\n",
    "        count = 0\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                rmse += (values[i] - values[j])**2\n",
    "                count += 1\n",
    "        if count > 0:\n",
    "            rmse = np.sqrt(rmse/count)\n",
    "            metric_rmses.append(rmse)\n",
    "    rmse_results.append(np.mean(metric_rmses))\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "rmse_df = pd.DataFrame(rmse_results, index=metrics, columns=['RMSE'])\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(rmse_df, \n",
    "            annot=True, \n",
    "            cmap='YlOrRd', \n",
    "            ax=ax2, \n",
    "            fmt='.2e',\n",
    "            cbar_kws={'label': 'Mean RMSE'})\n",
    "\n",
    "ax2.set_title('Consistency:\\nMean RMSE Across Platforms per Metric', \n",
    "              fontsize=14, \n",
    "              pad=20)\n",
    "ax2.set_xlabel('Mean RMSE', fontsize=12)\n",
    "ax2.set_ylabel('Metric', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(\"v3_bechmark_af.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bio_lib.custom_prodigy import predict_binding_affinity\n",
    "\n",
    "res = predict_binding_affinity(\"/Users/alessio/Documents/Repos/dr_sasa_python/data/PRODIGYdataset/1ACB.pdb\", selection=\"A,B\", output_dir=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extracting loss values from the file content\n",
    "loss_values = [\n",
    "    0.24, 0.10, -1.06, -1.61, -1.58, -0.11, -0.64, -2.54, -3.12, -1.35,\n",
    "    -3.29, -1.80, -4.27, -6.28, -2.02, -2.87, -3.39, -2.28, -4.46, -2.54,\n",
    "    -2.81, -3.49, -10.48, -2.64, -3.51, -14.84, -3.01, -4.51, -5.10, -5.02,\n",
    "    -5.24, -3.34, -6.71, -6.21, -3.37, -2.96, -4.37, -8.41, -4.06, -4.10,\n",
    "    -4.84, -4.90, -4.01, -4.51, -3.99, -4.34, -7.99, -4.92, -4.70, -11.73,\n",
    "    -4.50, -4.78, -5.65, -4.86, -11.32, -5.90, -7.05, -5.00, -5.22, -6.26,\n",
    "    -8.13, -12.18, -11.37, -5.84, -10.29, -8.89, -3.35, -7.57, -5.15, -5.61,\n",
    "    -6.37, -9.50, -6.32, -6.43, -5.89, -8.31, -6.62, -5.59, -10.87, -11.13\n",
    "]\n",
    "\n",
    "# Generate sequence indices\n",
    "steps = np.arange(1, len(loss_values) + 1)\n",
    "\n",
    "# Plot loss values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, loss_values, marker='o', linestyle='-', label=\"Loss\")\n",
    "\n",
    "# Formatting the plot\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.title(\"Loss over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "# Extracting additional values (i_ptm and ba_val)\n",
    "i_ptm_values = [\n",
    "    0.15, 0.19, 0.19, 0.19, 0.19, 0.16, 0.15, 0.21, 0.20, 0.16,\n",
    "    0.20, 0.16, 0.20, 0.20, 0.17, 0.20, 0.20, 0.15, 0.20, 0.17,\n",
    "    0.20, 0.22, 0.21, 0.17, 0.18, 0.21, 0.17, 0.17, 0.21, 0.22,\n",
    "    0.20, 0.17, 0.19, 0.23, 0.18, 0.18, 0.19, 0.26, 0.22, 0.18,\n",
    "    0.22, 0.24, 0.20, 0.18, 0.18, 0.20, 0.18, 0.25, 0.18, 0.18,\n",
    "    0.21, 0.19, 0.26, 0.21, 0.23, 0.19, 0.18, 0.24, 0.24, 0.26,\n",
    "    0.24, 0.18, 0.23, 0.21, 0.19, 0.25, 0.18, 0.17, 0.19, 0.23,\n",
    "    0.22, 0.18, 0.22, 0.18, 0.19, 0.21, 0.18, 0.24\n",
    "]\n",
    "\n",
    "ba_val_values = [\n",
    "    -6.09, -6.09, -6.29, -6.43, -6.35, -6.54, -6.58, -6.52, -6.71, -6.66,\n",
    "    -6.79, -6.62, -7.28, -8.21, -6.53, -6.54, -6.68, -6.76, -7.35, -6.71,\n",
    "    -6.42, -6.79, -10.14, -6.85, -6.97, -12.40, -6.75, -7.39, -7.54, -7.42,\n",
    "    -7.70, -6.80, -8.38, -8.02, -7.01, -6.68, -7.24, -9.10, -6.97, -7.25,\n",
    "    -7.39, -7.34, -7.33, -7.40, -7.25, -7.47, -8.82, -7.61, -7.56, -10.73,\n",
    "    -7.46, -7.42, -7.84, -7.73, -10.43, -7.93, -8.42, -7.57, -7.70, -8.00,\n",
    "    -8.86, -10.95, -10.53, -7.97, -10.04, -9.45, -6.73, -8.53, -7.63, -7.95,\n",
    "    -8.17, -9.66, -8.15, -8.42, -7.92, -9.12, -8.56, -8.04, -10.32, -10.42\n",
    "]\n",
    "\n",
    "# Ensuring all lists have the same length\n",
    "min_length = min(len(loss_values), len(i_ptm_values), len(ba_val_values))\n",
    "\n",
    "# Trimming all lists to the same length\n",
    "loss_values = loss_values[:min_length]\n",
    "\n",
    "i_ptm_values = i_ptm_values[:min_length] \n",
    "ba_val_values = ba_val_values[:min_length]\n",
    "steps = np.linspace(1, min_length, min_length)  # Scaling x-axis for better readability\n",
    "\n",
    "# Plot all values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(steps, loss_values, marker='o', linestyle='-', label=\"Loss\")\n",
    "\n",
    "plt.plot(steps, i_ptm_values, marker='d', linestyle='-.', label=\"i_PTM\")\n",
    "plt.plot(steps, ba_val_values, marker='v', linestyle='-', label=\"BA Value\")\n",
    "\n",
    "# Formatting the plot\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.title(\"Loss and Other Metrics Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio_lib_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
