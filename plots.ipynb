{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os, json\n",
    "import seaborn as sns\n",
    "\n",
    "def load_and_process_data(benchmark_path: str, results_path: str):\n",
    "    with open(benchmark_path) as f:\n",
    "        benchmark = json.load(f)\n",
    "    with open(results_path) as f:\n",
    "        results = json.load(f)\n",
    "        \n",
    "    df_benchmark = pd.DataFrame.from_dict(benchmark, orient='index')\n",
    "    \n",
    "    processed_results = {}\n",
    "    for pdb_id, data in results.items():\n",
    "        try:\n",
    "            processed_results[pdb_id] = {\n",
    "                'ba_val': data['ba_val'],\n",
    "                #'kd': data['kd'],\n",
    "                'CC': data['contacts']['CC'],\n",
    "                'CP': data['contacts']['CP'],\n",
    "                'AC': data['contacts']['AC'],\n",
    "                'PP': data['contacts']['PP'],\n",
    "                'AP': data['contacts']['AP'],\n",
    "                'AA': data['contacts']['AA'],\n",
    "                'nis_p': data['nis']['polar'],\n",
    "                'nis_a': data['nis']['aliphatic'],\n",
    "                'nis_c': data['nis']['charged'],\n",
    "                'execution_time': data['execution_time'][\"seconds\"]\n",
    "            }\n",
    "        except KeyError as e:\n",
    "            print(f\"Warning: Missing data for {pdb_id}: {e}\")\n",
    "            continue\n",
    "            \n",
    "    df_results = pd.DataFrame.from_dict(processed_results, orient='index')\n",
    "    \n",
    "    return df_benchmark, df_results\n",
    "\n",
    "def calculate_correlations(df_benchmark: pd.DataFrame, df_results: pd.DataFrame):\n",
    "    common_pdbs = sorted(set(df_benchmark.index) & set(df_results.index))\n",
    "    print(f\"Common PDB entries: {len(common_pdbs)}\")\n",
    "    \n",
    "    metrics = {\n",
    "        'ba_val': 'Binding Affinity',\n",
    "        'CC': 'Charged-Charged contacts',\n",
    "        'CP': 'Charged-Polar contacts',\n",
    "        'AC': 'Aliphatic-Charged contacts',\n",
    "        'PP': 'Polar-Polar contacts',\n",
    "        'AP': 'Aliphatic-Polar contacts',\n",
    "        'AA': 'Aliphatic-Aliphatic contacts',\n",
    "        'nis_p': 'NIS Polar',\n",
    "        'nis_a': 'NIS Aliphatic',\n",
    "        'nis_c': 'NIS Charged'\n",
    "    }\n",
    "    \n",
    "    correlations = []\n",
    "    for metric in metrics:\n",
    "        if metric in df_benchmark.columns and metric in df_results.columns:\n",
    "            bench_vals = df_benchmark.loc[common_pdbs, metric]\n",
    "            result_vals = df_results.loc[common_pdbs, metric]\n",
    "            pearson = stats.pearsonr(bench_vals, result_vals)\n",
    "            rmse = np.sqrt(np.mean((bench_vals - result_vals) ** 2))\n",
    "            correlations.append({\n",
    "                'Metric': metrics[metric],\n",
    "                'Pearson r': pearson[0],\n",
    "                'p-value': pearson[1],\n",
    "                'RMSE': rmse\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(correlations)\n",
    "\n",
    "def plot_correlations(df_benchmark: pd.DataFrame, df_results: pd.DataFrame, output_dir: str):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    common_pdbs = sorted(set(df_benchmark.index) & set(df_results.index))\n",
    "    \n",
    "    metrics = {\n",
    "        'ba_val': 'Binding Affinity',\n",
    "        'CC': 'Charged-Charged contacts',\n",
    "        'CP': 'Charged-Polar contacts',\n",
    "        'AC': 'Aliphatic-Charged contacts',\n",
    "        'PP': 'Polar-Polar contacts',\n",
    "        'AP': 'Aliphatic-Polar contacts',\n",
    "        'AA': 'Aliphatic-Aliphatic contacts',\n",
    "        'nis_p': 'NIS Polar',\n",
    "        'nis_a': 'NIS Aliphatic',\n",
    "        'nis_c': 'NIS Charged'\n",
    "    }\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, (metric, title) in enumerate(metrics.items()):\n",
    "        if i < len(axes):\n",
    "            bench_vals = df_benchmark.loc[common_pdbs, metric]\n",
    "            result_vals = df_results.loc[common_pdbs, metric]\n",
    "            \n",
    "            pearson = stats.pearsonr(bench_vals, result_vals)[0]\n",
    "            \n",
    "            ax = axes[i]\n",
    "            ax.scatter(bench_vals, result_vals, alpha=0.6)\n",
    "            ax.plot([min(bench_vals), max(bench_vals)], \n",
    "                   [min(bench_vals), max(bench_vals)], 'r--')\n",
    "            \n",
    "            ax.set_xlabel('Prodigy ORG')\n",
    "            ax.set_ylabel('Prodigy JAX')\n",
    "            ax.set_title(f'{title}\\nr = {pearson:.3f}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/correlations.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def add_sequence_lengths(df: pd.DataFrame, pdb_folder: str):\n",
    "    lengths = {}\n",
    "    for pdb_id in df.index:\n",
    "        try:\n",
    "            pdb_file = os.path.join(pdb_folder, f\"{pdb_id}.pdb\")\n",
    "            if os.path.exists(pdb_file):\n",
    "                with open(pdb_file, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                    # Count ATOM lines for chain A and B\n",
    "                    chain_a = sum(1 for line in lines if line.startswith('ATOM') and line[21] == 'A')\n",
    "                    chain_b = sum(1 for line in lines if line.startswith('ATOM') and line[21] == 'B')\n",
    "                    # Divide by typical number of atoms per residue (usually around 8-10)\n",
    "                    lengths[pdb_id] = {\n",
    "                        'chain_a_length': chain_a // 8,\n",
    "                        'chain_b_length': chain_b // 8\n",
    "                    }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pdb_id}: {e}\")\n",
    "            \n",
    "    # Add to DataFrame\n",
    "    length_df = pd.DataFrame.from_dict(lengths, orient='index')\n",
    "    return pd.concat([df, length_df], axis=1)\n",
    "\n",
    "def compare_sasa_results(gpu_dir: str, cpu_dir: str):\n",
    "    gpu_path = Path(gpu_dir)\n",
    "    cpu_path = Path(cpu_dir)\n",
    "    all_comparisons = []\n",
    "    all_sasa_values = []\n",
    "    \n",
    "    for protein_dir in gpu_path.glob(\"*\"):\n",
    "        print(\"\")\n",
    "        if not protein_dir.is_dir():\n",
    "            continue\n",
    "            \n",
    "        protein_name = protein_dir.name\n",
    "        gpu_csv = list(protein_dir.rglob(\"*.csv\"))\n",
    "        cpu_csv = list((cpu_path / protein_name).rglob(\"*.csv\"))\n",
    "        \n",
    "        if not gpu_csv or not cpu_csv:\n",
    "            continue\n",
    "        \n",
    "        gpu_data = pd.read_csv(gpu_csv[0])\n",
    "        gpu_data.resid = gpu_data.resid.astype(int)\n",
    "        gpu_data = gpu_data.sort_values(['chain', \"resname\", 'resid', 'atom'])\n",
    "        cpu_data = pd.read_csv(cpu_csv[0])\n",
    "        cpu_data.resid = cpu_data.resid.astype(int)\n",
    "        cpu_data = cpu_data.sort_values(['chain', \"resname\", 'resid', 'atom'])\n",
    "\n",
    "        if len(gpu_data) != len(cpu_data):\n",
    "            print(f\"Length mismatch in {protein_name}: GPU={len(gpu_data)}, CPU={len(cpu_data)}\")\n",
    "            continue\n",
    "        \n",
    "        comparison = pd.DataFrame({\n",
    "          'sasa_cpu': cpu_data['sasa'].values,\n",
    "          'sasa_gpu': gpu_data['sasa'].values,\n",
    "          'diff': abs(cpu_data['sasa'].values - gpu_data['sasa'].values),\n",
    "          'protein': protein_name,\n",
    "          'chain_gpu': gpu_data['chain'].values,\n",
    "          'resname_gpu': gpu_data['resname'].values, \n",
    "          'resid_gpu': gpu_data['resid'].values,\n",
    "          'atom_gpu': gpu_data['atom'].values,\n",
    "          'chain_cpu': cpu_data['chain'].values,\n",
    "          'resname_cpu': cpu_data['resname'].values,\n",
    "          'resid_cpu': cpu_data['resid'].values, \n",
    "          'atom_cpu': cpu_data['atom'].values\n",
    "        })\n",
    "        \n",
    "        all_sasa_values.append(comparison)\n",
    "        \n",
    "        rmse = np.sqrt(np.mean(comparison['diff']**2))\n",
    "        correlation = stats.pearsonr(comparison['sasa_cpu'], comparison['sasa_gpu'])[0]\n",
    "        \n",
    "        all_comparisons.append({\n",
    "            'protein': protein_name,\n",
    "            'rmse': rmse,\n",
    "            'correlation': correlation,\n",
    "            'mean_diff': comparison['diff'].mean(),\n",
    "            'max_diff': comparison['diff'].max(),\n",
    "            'num_atoms': len(comparison),\n",
    "            'num_nonzero': len(comparison[comparison['sasa_gpu'] > 0])\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(all_comparisons)\n",
    "    all_sasa_df = pd.concat(all_sasa_values)\n",
    "    \n",
    "    # Add high_rmse column to all_sasa_df\n",
    "    high_rmse_proteins = set(summary_df[summary_df['rmse'] > 2]['protein'])\n",
    "    all_sasa_df['high_rmse'] = all_sasa_df['protein'].isin(high_rmse_proteins)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # RMSE scatter plot\n",
    "    ax1.scatter(summary_df['num_atoms'], summary_df['rmse'], alpha=0.6)\n",
    "    for i, txt in enumerate(summary_df['protein']):\n",
    "        if summary_df['rmse'].iloc[i] > 2:\n",
    "            ax1.annotate(txt, (summary_df['num_atoms'].iloc[i], summary_df['rmse'].iloc[i]))\n",
    "    ax1.set_xlabel('Number of Atoms')\n",
    "    ax1.set_ylabel('RMSE (Å²)')\n",
    "    ax1.set_title('RMSE GPU and CPU vs Structure Size')\n",
    "    \n",
    "    # SASA values comparison with color coding\n",
    "    normal_points = all_sasa_df[~all_sasa_df['high_rmse']]\n",
    "    high_rmse_points = all_sasa_df[all_sasa_df['high_rmse']]\n",
    "    \n",
    "    ax2.scatter(normal_points['sasa_cpu'], normal_points['sasa_gpu'], alpha=0.1, color='blue')\n",
    "    \n",
    "    max_val = max(all_sasa_df['sasa_cpu'].max(), all_sasa_df['sasa_gpu'].max())\n",
    "    ax2.plot([0, max_val], [0, max_val], 'k--')\n",
    "    ax2.set_xlabel('CPU SASA (Å²)')\n",
    "    ax2.set_ylabel('GPU SASA (Å²)')\n",
    "    ax2.set_title('CPU vs GPU SASA Values')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sasa_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return summary_df, all_sasa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = \"./benchmark_af/dataset.json\"\n",
    "results = \"./benchmark_af/20250126_140901_gpu/combined_results.json\"\n",
    "output = \"output_comp\"\n",
    "dataset = \"./benchmark_af/PRODIGYdataset/\" # make sure you have the dataset\n",
    "os.makedirs(output, exist_ok=True)\n",
    "df_benchmark, df_results = load_and_process_data(benchmark, results)\n",
    "correlations = calculate_correlations(df_benchmark, df_results)\n",
    "print(\"\\nCorrelation Analysis:\")\n",
    "print(correlations.to_string(index=False))\n",
    "correlations.to_csv(f'{output}/correlations.csv', index=False)\n",
    "plot_correlations(df_benchmark, df_results, output)\n",
    "\n",
    "# Save processed DataFrames\n",
    "df_benchmark.to_csv(f'{output}/benchmark_processed.csv')\n",
    "df_results.to_csv(f'{output}/results_processed.csv')\n",
    "\n",
    "df = add_sequence_lengths(df_results, dataset)\n",
    "df['total_length'] = df['chain_a_length'] + df['chain_b_length']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['total_length'], df['execution_time'])\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(df['total_length'], df['execution_time'], 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(df['total_length'], p(df['total_length']), \"r--\", alpha=0.8)\n",
    "\n",
    "# Calculate correlation\n",
    "corr = df['total_length'].corr(df['execution_time'])\n",
    "\n",
    "plt.xlabel('Total Sequence Length (residues)')\n",
    "plt.ylabel('Execution Time (s)')\n",
    "plt.title(f'Execution Time vs Sequence Length\\nCorrelation: {corr:.3f}')\n",
    "plt.grid(True, alpha=0.3)\n",
    "summary_df, all_sasa_df = compare_sasa_results(\"./benchmark_af/20250126_140901_gpu\", \"./benchmark_af/20250127_160612_cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bio_lib.custom_prodigy import predict_binding_affinity\n",
    "\n",
    "predict_binding_affinity(\"/Users/alessio/Documents/Repos/bio_lib/3bzd.pdb\", save_results=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio_lib_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
